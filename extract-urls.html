<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="style.css">
  <script type="module" src="js/common.js"></script>
  <title>Extract URLs</title>
  <style>
    .input-group {
      margin-bottom: 20px;
    }

    .sitemaps-list {
      background: #f8f9fa;
      padding: 15px;
      border-radius: 4px;
      border: 1px solid #ddd;
      max-height: 200px;
      overflow-y: auto;
      margin-bottom: 20px;
    }

    .sitemap-item {
      padding: 8px;
      margin-bottom: 8px;
      background: white;
      border: 1px solid #eee;
      border-radius: 4px;
    }

    #urlResults {
      width: 100%;
      height: 500px;
      padding: 10px;
      font-size: 16px;
      border: 1px solid #ddd;
      border-radius: 4px;
      font-family: monospace;
      resize: vertical;
    }

    .stats {
      margin-top: 10px;
      font-size: 14px;
      color: #666;
    }

    .loading {
      display: inline-block;
      margin-left: 10px;
    }

    .fallback-section {
      display: none;
      margin-top: 20px;
      padding: 20px;
      background: #f8f9fa;
      border-radius: 8px;
      border: 1px solid #ddd;
    }

    .sitemaps-section {
      display: none;
    }

    .sitemaps-section.visible {
      display: block;
    }

    .fallback-section {
      display: none;
    }

    .fallback-section.visible {
      display: block;
    }

    .error {
      color: #dc3545;
    }

    .status {
      margin: 10px 0;
    }

    .success {
      color: #28a745;
    }

    .container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
    }
  </style>
</head>

<body>
  <div class="container">
    <h1>Extract URLs</h1> 
    <p>Extract URLs from a website for analysis with the <a href="https://lab.simonwisdom.com/llm-web-parse">LLM Web Parser</a>.</p>
    <div class="input-group">
      <input type="url" id="urlInput" placeholder="Enter website URL (e.g., https://example.com)" required>
      <button id="searchButton">Extract URLs</button>
    </div>
    <div id="status" class="status"></div>

    <div id="sitemapsSection" class="sitemaps-section">
      <h2>Found Sitemaps</h2>
      <div id="sitemapsList" class="sitemaps-list"></div>
    </div>

    <h2>Extracted URLs</h2>
    <textarea id="urlResults" readonly></textarea>
    <div id="urlStats" class="stats"></div>
  </div>

  <script type="module">
    const commonPaths = [
      '/sitemap.xml',
      '/sitemap_index.xml',
      '/sitemaps/sitemap.xml',
      '/sitemap/sitemap.xml',
      '/sitemap.php',
      '/sitemap.html',
      '/sitemap.txt',
      '/wp-sitemap.xml',
      '/feed/',
      '/sitemap_products.xml',
      '/component/osmap/xml',
      '/site-map.html',
      '/site-map/',
      '/pages/',
      '/archive/'
    ]

    class SitemapFinder {
      constructor() {
        this.urlInput = document.getElementById('urlInput')
        this.searchButton = document.getElementById('searchButton')
        this.urlResults = document.getElementById('urlResults')
        this.sitemapsList = document.getElementById('sitemapsList')
        this.status = document.getElementById('status')
        this.urlStats = document.getElementById('urlStats')
        this.sitemapsSection = document.getElementById('sitemapsSection')
        this.foundSitemaps = new Map() // URL -> parsed URLs
        this.proxyBaseUrl = 'https://lab-proxy.vercel.app/api/proxy'
        this.allUrls = new Set() // Store all unique URLs

        this.searchButton.addEventListener('click', () => this.startSearch())
      }

      async extractHtmlUrls() {
        try {
          const baseUrl = this.normalizeUrl(this.urlInput.value);
          this.status.textContent = 'Extracting URLs from webpage...';

          const jinaResponse = await fetch(`https://r.jina.ai/${encodeURIComponent(baseUrl)}`, {
            method: 'GET',
            headers: {
              'Authorization': 'Bearer jina_98f5359b8ac94d8f81da80ce4e0fdd192mA17qpogTYwvkIrTPWJ6Qej-xn3',
              'X-With-Links-Summary': 'true',
              'X-Retain-Images': 'none'
            }
          });

          if (!jinaResponse.ok) {
            throw new Error('Failed to extract URLs from webpage');
          }

          const markdownContent = await jinaResponse.text();
          const linksSection = markdownContent.split('Links/Buttons:')[1] || '';
          const rawUrls = Array.from(linksSection.matchAll(/\((https?:\/\/[^\s)]+)\)/g)).map(match => match[1]);
          const uniqueUrls = Array.from(new Set(rawUrls)).filter(url => !url.startsWith('mailto:'));

          if (uniqueUrls.length === 0) {
            throw new Error('No valid URLs found in webpage');
          }

          this.displayUrls(uniqueUrls);
          this.status.textContent = `Successfully extracted ${uniqueUrls.length} URLs from webpage`;
          this.status.className = 'status success';
          return uniqueUrls;
        } catch (error) {
          this.status.textContent = `Error: ${error.message}`;
          this.status.className = 'error';
          throw error;
        }
      }

      async proxyFetch(url) {
        const proxyUrl = `${this.proxyBaseUrl}?url=${encodeURIComponent(url)}`
        try {
          const response = await fetch(proxyUrl)
          if (response.status === 403) {
            throw new Error('Access denied by the target website')
          }
          if (!response.ok) {
            throw new Error(`Failed to fetch ${url}`)
          }
          return response
        } catch (error) {
          console.warn(`Proxy fetch error for ${url}:`, error)
          throw error
        }
      }

      async startSearch() {
        this.resetUI();
        this.status.textContent = 'Searching for sitemaps...';
        this.searchButton.disabled = true;
        this.allUrls.clear();

        try {
          const baseUrl = this.normalizeUrl(this.urlInput.value);

          if (!this.isValidUrl(baseUrl)) {
            throw new Error('Please enter a valid URL');
          }

          await this.checkRobotsTxt(baseUrl);
          await this.checkCommonPaths(baseUrl);
          await this.checkMainPageLinks(baseUrl);

          if (this.foundSitemaps.size === 0) {
            // No sitemaps found, automatically try HTML extraction
            this.status.textContent = 'No sitemaps found. Extracting URLs from webpage...';
            await this.extractHtmlUrls();
          } else {
            this.sitemapsSection.classList.add('visible');
            this.displayUrls(Array.from(this.allUrls));
            this.status.textContent = `Successfully extracted ${this.allUrls.size} URLs from ${this.foundSitemaps.size} sitemap(s)`;
          }
        } catch (error) {
          this.status.textContent = `Error: ${error.message}`;
          this.status.className = 'error';
        } finally {
          this.searchButton.disabled = false;
        }
      }

      resetUI() {
        this.sitemapsList.innerHTML = '';
        this.urlResults.value = '';
        this.urlStats.textContent = '';
        this.status.textContent = '';
        this.status.className = 'status';
        this.allUrls.clear();
        if (this.fallbackSection) this.fallbackSection.classList.remove('visible');
        if (this.sitemapsSection) this.sitemapsSection.classList.remove('visible');
      }

      displayUrls(urls) {
        this.urlResults.value = urls.join('\n');
        this.urlStats.textContent = `Found ${urls.length} URLs`;
      }

      normalizeUrl(url) {
        if (!url.startsWith('http://') && !url.startsWith('https://')) {
          url = 'https://' + url
        }
        return url.replace(/\/$/, '')
      }

      isValidUrl(url) {
        try {
          new URL(url)
          return true
        } catch {
          return false
        }
      }

      async checkRobotsTxt(baseUrl) {
        try {
          const response = await this.proxyFetch(`${baseUrl}/robots.txt`)
          const text = await response.text()
          const sitemapUrls = text.match(/Sitemap: (.*?)$/gm)
          if (sitemapUrls) {
            for (const line of sitemapUrls) {
              const url = line.replace('Sitemap:', '').trim()
              await this.addSitemap(url)
            }
          }
        } catch (error) {
          console.warn('Error checking robots.txt:', error)
        }
      }

      async checkCommonPaths(baseUrl) {
        for (const path of commonPaths) {
          try {
            const url = `${baseUrl}${path}`
            const response = await this.proxyFetch(url)
            if (response.ok) {
              await this.addSitemap(url)
            }
          } catch (error) {
            console.warn(`Error checking ${path}:`, error)
          }
        }
      }

      async checkMainPageLinks(baseUrl) {
        try {
          const response = await this.proxyFetch(baseUrl)
          const text = await response.text()
          const parser = new DOMParser()
          const doc = parser.parseFromString(text, 'text/html')

          const links = doc.querySelectorAll('a[href*="sitemap"], link[rel="alternate"]')
          for (const link of links) {
            const href = link.href || link.getAttribute('href')
            if (href) {
              try {
                const url = new URL(href, baseUrl)
                await this.addSitemap(url.href)
              } catch (error) {
                console.warn('Invalid URL:', href)
              }
            }
          }
        } catch (error) {
          console.warn('Error checking main page:', error)
        }
      }

      async addSitemap(url) {
        if (!this.foundSitemaps.has(url)) {
          const urls = await this.parseSitemap(url)
          if (urls.length > 0) {
            this.foundSitemaps.set(url, urls)
            // Add URLs to the all URLs set
            urls.forEach(url => this.allUrls.add(url))
            // Add sitemap to UI without click handler
            this.addSitemapToUI(url, urls)
          }
        }
      }

      async parseSitemap(url) {
        try {
          const response = await this.proxyFetch(url)
          const text = await response.text()
          const parser = new DOMParser()
          const doc = parser.parseFromString(text, 'text/xml')

          // Handle sitemap index files
          const sitemapNodes = doc.querySelectorAll('sitemap loc')
          if (sitemapNodes.length > 0) {
            let allUrls = []
            for (const node of sitemapNodes) {
              const sitemapUrl = node.textContent
              const urls = await this.parseSitemap(sitemapUrl)
              allUrls = allUrls.concat(urls)
            }
            return allUrls
          }

          // Handle regular sitemaps
          const urlNodes = doc.querySelectorAll('url loc')
          return Array.from(urlNodes).map(node => node.textContent)
        } catch (error) {
          console.warn('Error parsing sitemap:', error)
          return []
        }
      }

      addSitemapToUI(url, urls) {
        const item = document.createElement('div')
        item.className = 'sitemap-item'
        item.textContent = `${url} (${urls.length} URLs)`
        this.sitemapsList.appendChild(item)
      }
    }

    // Initialize the app
    new SitemapFinder()
  </script>
</body>
</html>